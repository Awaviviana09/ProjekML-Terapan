# -*- coding: utf-8 -*-
"""Beres-Dicoding

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17eCRaJW6-wHW5dV_ZNLwPJ30mOiIRiqG

# **Predictive Analytics: Kualitas Apel**

---

*oleh: [Zahwa Genoveva](https://www.dicoding.com/users/zahwa_genoveva_vwyu/academies)*

*Proyek Submission 1 - Machine Learning
Terapan Dicoding*
<center>
<img src="https://cdn1-production-images-kly.akamaized.net/xBRT773xJ9vvZx12J6fN1IIVhko=/1200x675/smart/filters:quality(75):strip_icc():format(jpeg)/kly-media-production/medias/2792644/original/076377400_1556614591-aaron-blanco-tejedor-390113-unsplash.jpg" align="justify">
</center>

## **1. Mengimpor pustaka/modul python yang dibutuhkan**
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import zipfile

# Import modules for splitting dataset and preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler

# Import machine learning models
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import BernoulliNB
from xgboost import XGBClassifier

# Import evaluation metrics
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

"""Pustaka ini memberikan kerangka lengkap untuk mengembangkan model pembelajaran mesin, memproses data, dan mengevaluasi kinerja model.

## **2. Data Understanding**

Data Understanding adalah langkah awal dalam proses analisis data yang bertujuan untuk mengumpulkan, menjelajahi, dan memahami data yang tersedia.

### **2.1 Menyiapkan kredensial akun Kaggle**
"""

files.upload()

""" Di cell ini, kita meng-upload file yang diperlukan untuk analisis menggunakan fungsi upload() dari modul files"""

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

"""disini akan dilakukan pengaturan untuk menggunakan API Kaggle.

### **2.2 Mengunduh dan Menyiapkan Dataset**

![Image of Dataset](https://i.postimg.cc/CKJ0sBXT/Screenshot-2024-10-10-204041.png)

ðŸ“Š Informasi dataset dapat dilihat pada tabel di bawah ini:


| **Jenis**      | **Keterangan**                                                                                           |
|----------------|----------------------------------------------------------------------------------------------------------|
| **Title**      | Apple Quality                                                                                           |
| **Source**     | Kaggle    
| Sumber                      | [Kaggle Dataset : Apple Quality Dataset](https://www.kaggle.com/datasets/nelgiriyewithana/apple-quality/data) |                                                                                            |
| **Maintainer** | Nidula Elgiriyewithana âš¡                                                                                |
| **License**    | Other (specified in description)                                                                         |
| **Visibility** | Publik                                                                                                |
| **Tags**       | Computer Science, Education, Food, Data Visualization, Classification, Exploratory Data Analysis       |
| **Usability**  | 10.00                                                                                                   |
"""

!kaggle datasets download -d nelgiriyewithana/apple-quality

zip_ref = zipfile.ZipFile('/content/apple-quality.zip', 'r')
zip_ref.extractall('/content/')
zip_ref.close()

df = pd.read_csv('/content/apple_quality.csv')

"""### **2.2 Exploratory Data Analysis (EDA)**

Exploratory Data Analysis (EDA) adalah langkah awal dalam analisis data yang bertujuan untuk memahami dan menggali informasi dari dataset sebelum melakukan analisis lebih lanjut atau modeling. Tujuan utama EDA adalah membantu melihat data sebelum membuat asumsi apa pun. EDA dapat membantu mengidentifikasi kesalahan yang jelas, serta memahami pola dalam data dengan lebih baik, mendeteksi outlier atau kejadian yang tidak wajar, dan menemukan hubungan yang menarik di antara variabel.

**2.2.1 EDA - Deskripsi Variabel**

Deskripsi Variabel dalam konteks Exploratory Data Analysis (EDA) adalah langkah di mana kita menganalisis dan menjelaskan karakteristik dari setiap variabel dalam dataset.
"""

df

"""

*   Kolom: A_id, Size, Weight, Sweetness, Crunchiness, Juiciness, Ripeness, Acidity, Quality
*   Jumlah Baris: 4002


*   Nilai NaN: Ditemukan di baris ke-4000, menunjukkan data hilang.
"""

# Menampilkan beberapa baris pertama dari dataset
df.head()

"""Output menunjukkan lima baris pertama dari DataFrame yang berisi informasi mengenai kualitas apel"""

# Menampilkan informasi dasar tentang dataset
df.info()

"""Hasil dari eksekusi metode df.info() menunjukkan:

Ada 6 kolom numerik yang memiliki tipe data float64, yaitu: Size, Weight, Sweetness, Crunchiness, Juiciness, dan Ripeness. Sementara itu, terdapat 2 kolom dengan tipe data object, yaitu: Acidity dan Quality. Namun, pada data asli, kolom Acidity seharusnya bertipe float64, dan kita akan melakukan perubahan pada kolom tersebut.
"""

# Menampilkan statistik deskriptif dari dataset
df.describe()

df.shape

"""Hasil dari df.shape adalah (4001, 9), yang berarti:

4001: Jumlah baris dalam DataFrame.
9: Jumlah kolom dalam DataFrame.

Jadi, DataFrame df memiliki 4001 baris data dan 9 kolom variabel.

### **2.2.2 EDA - Menangani Missing Value dan Outliers**

Exploratory Data Analysis (EDA) dalam menangani missing values melibatkan teknik seperti menghapus data yang hilang (drop), mengganti dengan nilai rata-rata (mean), median, modus, atau menggunakan metode imputasi lebih kompleks seperti KNN atau regresi. Sedangkan untuk outliers, penanganannya meliputi identifikasi menggunakan metode statistik (IQR, z-score), kemudian memilih untuk menghapus, merubah, atau membiarkan outliers tergantung pada pengaruhnya terhadap model dan data.
"""

# Menghapus kolom "A_id" dari DataFrame df
df.drop("A_id",axis=1,inplace=True)

"""Dikarenakan kolom A_id tidak mempengaruhi model maka akan di drop / dihapus."""

df.describe()

# Cek nilai yang hilang
missing_values = df.isnull().sum()
print("Missing values in each column:\n", missing_values)

"""Menghitung jumlah nilai yang hilang di setiap kolom untuk mengetahui apakah ada missing values yang perlu ditangani."""

# Menghapus baris yang memiliki nilai hilang dari DataFrame df
df_cleaned = df.dropna()

"""baris-baris yang memiliki nilai hilang dihapus dari DataFrame df menggunakan metode dropna(). Hasilnya disimpan dalam DataFrame baru yang disebut df_cleaned, sehingga DataFrame ini hanya berisi data lengkap."""

# Menampilkan jumlah nilai yang hilang setelah menghapus baris dengan nilai hilang
print("\nJumlah Nilai yang Hilang Setelah Menangani:\n", df_cleaned.isnull().sum())

"""Menampilkan Jumlah Nilai yang Hilang Setelah Penanganan"""

# Memeriksa jumlah duplikasi dalam DataFrame yang telah dibersihkan
print(f"Jumlah duplikasi dalam data: {df_cleaned.duplicated().sum()}")

"""Menghitung berapa banyak baris duplikat yang ada dalam DataFrame setelah proses pembersihan."""

# Menghitung dan menampilkan proporsi masing-masing kategori dalam kolom 'Quality' dari DataFrame df
df.Quality.value_counts(normalize=True)

# Menampilkan nilai unik dalam kolom 'Acidity'
print("Nilai Unik dalam Kolom 'Acidity':")
print(df['Acidity'].unique())

"""Menghitung Proporsi Kategori dalam Kolom 'Quality'"""

# Mengganti nilai non-numeric dengan NaN
df['Acidity'] = pd.to_numeric(df['Acidity'], errors='coerce')

"""Menampilkan Nilai Unik dalam Kolom 'Acidity'"""

# Menghapus baris yang memiliki NaN di kolom 'Acidity'
df = df.dropna(subset=['Acidity'])

"""Mengganti Nilai Non-Numeric dengan NaN
python
"""

# Mengonversi kolom 'Acidity' ke float64
df.loc[:, 'Acidity'] = df['Acidity'].astype('float64')

"""Mengonversi tipe data di kolom 'Acidity' menjadi float64 agar dapat digunakan dalam analisis numerik."""

# Menampilkan informasi tentang DataFrame setelah penanganan
print("Informasi Setelah Penanganan Kolom 'Acidity':")
df.info()

"""Dapat kita lihat:

Jumlah data Float64 ada 7 dan object ada 1.

Membuat Boxplot untuk Identifikasi Outliers
"""

import warnings

# Mengabaikan FutureWarnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# Plotting boxplot untuk mengidentifikasi outliers
plt.figure(figsize=(10, 5))
sns.boxplot(data=df)
plt.title("Boxplot untuk Mengidentifikasi Outliers")
plt.show()

"""**Visualisasi Outlier**

*Menghapus outliers yang ada pada dataset*  


Pada kasus ini, kita akan mendeteksi outliers dengan teknik visualisasi data (boxplot). Kemudian, menangani outliers dengan teknik IQR method.


```
IQR = Inter Quartile Range
IQR = Q3 - Q1
```

Mengidentifikasi outliers menggunakan IQR hanya untuk kolom numerik
"""

df_cleaned = df.dropna()
numeric_cols = df_cleaned.select_dtypes(include=np.number).columns  # Memilih kolom numerik

Q1 = df_cleaned[numeric_cols].quantile(0.25)
Q3 = df_cleaned[numeric_cols].quantile(0.75)
IQR = Q3 - Q1

"""Menentukan batas untuk outliers"""

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

"""Mengidentifikasi outliers"""

outliers = ((df_cleaned[numeric_cols] < lower_bound) | (df_cleaned[numeric_cols] > upper_bound)).any(axis=1)

"""Menampilkan jumlah outliers"""

print(f"\nJumlah Outliers: {outliers.sum()}")

"""Menghapus outliers dari dataset"""

df_final = df_cleaned[~outliers]

df_final.shape

"""Dari output yang dihasilkan, (3790, 8) berarti DataFrame df_final memiliki 3790 baris dan 8 kolom.

Visualisasi distribusi data setelah menghapus outliers
"""

plt.figure(figsize=(12, 6))
sns.boxplot(data=df_final[numeric_cols])
plt.title("Boxplot Setelah Menghapus Outliers")
plt.show()

"""**Visualisasi Outlier**"""

# Menggunakan dataset yang sudah ada (df)
df_outlier = df.select_dtypes(exclude=['object'])

# Looping untuk membuat boxplot untuk setiap kolom
for column in df_outlier:
    plt.figure(figsize=(8, 5))
    sns.boxplot(data=df_outlier, x=column)

    # Menambahkan judul
    plt.title(f'Boxplot untuk {column}')

    # Menampilkan plot
    plt.show()

df_final.describe()

"""**2.2.3 EDA - Univariate Analysis**"""

def univariate_analysis_hist(df):
    # Visualisasi histogram untuk semua kolom numerik
    df.select_dtypes(include=['float64', 'int64']).hist(bins=50, figsize=(15, 10))
    plt.tight_layout()  # Menambahkan layout agar tidak bertumpuk
    plt.show()

# Panggil fungsi untuk melakukan univariate analysis
univariate_analysis_hist(df_cleaned)

"""Secara keseluruhan, visualisasi ini menunjukkan bahwa objek-objek yang dianalisis memiliki karakteristik yang cukup seragam, kecuali untuk atribut kualitas yang cenderung sangat terpusat pada satu nilai. Ini bisa mengindikasikan bahwa proses produksi atau seleksi objek ini cukup konsisten dalam menghasilkan produk dengan kualitas yang hampir sama.

### **2.2.4 EDA - Multivariate Analysis**

### **Encoding Fitur Kategori (Categorical Encoding)**
"""

# Mengonversi kolom kategori ke numerik
def convert_categorical_to_numerical(df):
    # Menggunakan label encoding untuk kolom kategori
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()

    for col in df.select_dtypes(include='object').columns:
        df[col] = le.fit_transform(df[col])

    return df

"""### **Menampilkan pairplot**"""

def plot_pairplot(df):
    # Mengonversi kolom kategori menjadi numerik
    df_numeric = convert_categorical_to_numerical(df)

    # Pairplot untuk analisis lebih dalam
    sns.pairplot(df_numeric, hue='Quality', diag_kind='kde')
    plt.suptitle('Pairplot of Features Colored by Quality', y=1.02)
    plt.show()

# Panggil fungsi untuk menampilkan pairplot
plot_pairplot(df_cleaned)

"""Secara keseluruhan, pairplot ini membantu kita memahami kompleksitas hubungan antara berbagai karakteristik (seperti ukuran, berat, kemanisan, dsb.) dari suatu objek. Kita bisa melihat variabel mana yang saling terkait, variabel mana yang tidak, dan variabel mana yang mungkin mempengaruhi kualitas.

### **Melakukan pengecekan korelasi**
"""

# Fungsi untuk menampilkan matriks korelasi
def plot_correlation_matrix(df):
    # Mengonversi kolom kategori menjadi numerik
    df_numeric = convert_categorical_to_numerical(df)

    plt.figure(figsize=(15, 10))

    # Korelasi antar fitur
    correlation_matrix = df_numeric.corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)
    plt.title('Matriks Korelasi')
    plt.show()

# Panggil fungsi untuk menampilkan matriks korelasi
plot_correlation_matrix(df_cleaned)

"""Berdasarkan matriks korelasi ini, kita bisa menyimpulkan bahwa kualitas suatu objek dipengaruhi oleh beberapa faktor seperti ukuran, juiciness, acidity, sweetness, dan ripeness. Objek yang lebih besar, lebih juicy, lebih asam, dan kurang manis serta kurang matang cenderung memiliki kualitas yang lebih baik.

# **3. Data Preparation**

Data Preparation adalah proses menyiapkan data mentah sehingga layak untuk diproses dan dianalisis lebih lanjut. Langkah-langkah utama mencakup pengumpulan, pembersihan, dan pelabelan data mentah ke dalam bentuk yang cocok untuk algoritma machine learning (ML), kemudian menjelajahi dan memvisualisasikan data. Data Preparation dapat memerlukan waktu hingga 80% dari waktu yang digunakan untuk proyek ML. Penggunaan alat persiapan data khusus penting untuk mengoptimalkan proses ini.

### **3.1 Train-Test-Split**

Kita akan membagi dataset menjadi data latih (train) dan data uji (test). Tujuan langkah ini sebelum proses lainnya adalah agar kita tidak mengotori data uji dengan informasi yang kita dapat dari data latih.

#### Menyiapkan Data untuk Model
"""

X = df.drop('Quality', axis=1)
y = df['Quality']

"""####Mengonversi Kelas Target ke Format Numerik"""

# Konversi kelas target ke format numerik
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)  # Mengubah 'bad' dan 'good' menjadi 0 dan 1

"""mengubah nilai kategori dalam kolom target y ('bad' dan 'good') menjadi format numerik (0 dan 1).

####Membagi Data Menjadi Training dan Testing
"""

# Split data menjadi training dan testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""20% dari data akan digunakan untuk pengujian, sementara 80% sisanya akan digunakan untuk pelatihan."""

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""####Normalisasi Fitur dengan StandardScaler"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""####Melakukan Skala Data menggunakan StandardScaler (Duplicated)"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Normalisasi data pelatihan
X_test_scaled = scaler.transform(X_test)        # Normalisasi data pengujian

"""####Membuat DataFrame Hasil Normalisasi"""

# Membuat DataFrame dari X_train untuk mendapatkan nilai asli
original_values = pd.DataFrame(X_train, columns=X.columns)

# Membuat DataFrame untuk menampilkan hasil normalisasi
normalized_df = pd.DataFrame(X_train_scaled, columns=X.columns)

# Menampilkan beberapa baris pertama dari DataFrame hasil normalisasi
print("Hasil Normalisasi:")
print(normalized_df.head())

# Menampilkan nilai asli untuk perbandingan
comparison_df = pd.concat([original_values.reset_index(drop=True), normalized_df.reset_index(drop=True)], axis=1)
comparison_df.columns = [f"Original {col}" for col in X.columns] + [f"Normalized {col}" for col in X.columns]

print("\nPerbandingan Nilai Asli dan Nilai Normalisasi:")
print(comparison_df.head())

"""####Inisialisasi MinMaxScaler dan Normalisasi Data"""

# Inisialisasi MinMaxScaler
scaler = MinMaxScaler()

# Fit dan transform pada data pelatihan
X_train_scaled = scaler.fit_transform(X_train)

# Transformasi data uji
X_test_scaled = scaler.transform(X_test)

print("Data setelah normalisasi:")
print(X_train_scaled[:5])  # Menampilkan 5 data pertama

"""## **4. Model Development**"""

# Initialize models
knn = KNeighborsClassifier()
rf = RandomForestClassifier()
svm = SVC()  # You can customize parameters if needed
nb = GaussianNB()
dt = DecisionTreeClassifier()
xgb_model = xgb.XGBClassifier()  # Make sure to import and install XGBoost

# Fit models to your training data
knn.fit(X_train, y_train)
rf.fit(X_train, y_train)
svm.fit(X_train, y_train)
nb.fit(X_train, y_train)
dt.fit(X_train, y_train)
xgb_model.fit(X_train, y_train)

# Define the evaluate_models function
def evaluate_models(X_test, y_test, models):
    results = []
    for name, model in models.items():
        y_pred = model.predict(X_test)

        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='macro')
        recall = recall_score(y_test, y_pred, average='macro')

        results.append({'Model': name, 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall})

    return pd.DataFrame(results)

# Create a dictionary of the models
models = {
    'KNN': knn,
    'Random Forest': rf,
    'SVM': svm,
    'Naive Bayes': nb,
    'Decision Tree': dt,
    'XGBoost': xgb_model
}

# Evaluate the models
results_df = evaluate_models(X_test, y_test, models)
print(results_df)

"""## **5. Evaluasi Model**

###Confussion Matrix

**Visualisasi Algoritma KNN**
"""

# Melatih model KNN
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)
y_pred_knn = knn_model.predict(X_test)

# Evaluasi model KNN
def evaluate_knn(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    class_report = classification_report(y_true, y_pred, target_names=label_encoder.classes_)
    conf_matrix = confusion_matrix(y_true, y_pred)

    print("\n===== Evaluasi Model: KNN =====")
    print(f"Akurasi: {accuracy:.4f}\n")
    print("Laporan Klasifikasi:")
    print(class_report)

    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    plt.title('Matriks Kebingungan: KNN')
    plt.xlabel('Prediksi')
    plt.ylabel('Kebenaran')
    plt.show()

    return accuracy  # Mengembalikan akurasi

# Panggil fungsi evaluasi KNN
knn_accuracy = evaluate_knn(y_test, y_pred_knn)

"""**Visualisasi Algoritma Random Forest**"""

# Melatih model Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

# Evaluasi model Random Forest
def evaluate_rf(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    class_report = classification_report(y_true, y_pred, target_names=label_encoder.classes_)
    conf_matrix = confusion_matrix(y_true, y_pred)

    print("\n===== Evaluasi Model: Random Forest =====")
    print(f"Akurasi: {accuracy:.4f}\n")
    print("Laporan Klasifikasi:")
    print(class_report)

    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    plt.title('Matriks Kebingungan: Random Forest')
    plt.xlabel('Prediksi')
    plt.ylabel('Kebenaran')
    plt.show()

    return accuracy  # Mengembalikan akurasi

# Panggil fungsi evaluasi Random Forest
rf_accuracy = evaluate_rf(y_test, y_pred_rf)

"""**Visualisasi Algoritma XGBoost**"""

# Melatih model XGBoost
xgb_model = XGBClassifier(eval_metric='mlogloss')
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)

# Evaluasi model XGBoost
def evaluate_xgb(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    class_report = classification_report(y_true, y_pred, target_names=label_encoder.classes_)
    conf_matrix = confusion_matrix(y_true, y_pred)

    print("\n===== Evaluasi Model: XGBoost =====")
    print(f"Akurasi: {accuracy:.4f}\n")
    print("Laporan Klasifikasi:")
    print(class_report)

    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    plt.title('Matriks Kebingungan: XGBoost')
    plt.xlabel('Prediksi')
    plt.ylabel('Kebenaran')
    plt.show()

    return accuracy  # Mengembalikan akurasi

# Panggil fungsi evaluasi XGBoost
xgb_accuracy = evaluate_xgb(y_test, y_pred_xgb)

"""**Visualisasi Algoritma SVC**"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Melatih model SVM
svm_model = SVC()
svm_model.fit(X_train, y_train)
y_pred_svm = svm_model.predict(X_test)

# Evaluasi model SVM
def evaluate_svm(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    class_report = classification_report(y_true, y_pred, target_names=label_encoder.classes_)
    conf_matrix = confusion_matrix(y_true, y_pred)

    print("\n===== Evaluasi Model: SVM =====")
    print(f"Akurasi: {accuracy:.4f}\n")
    print("Laporan Klasifikasi:")
    print(class_report)

    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    plt.title('Matriks Kebingungan: SVM')
    plt.xlabel('Prediksi')
    plt.ylabel('Kebenaran')
    plt.show()

    return accuracy  # Mengembalikan akurasi

# Panggil fungsi evaluasi SVM
svm_accuracy = evaluate_svm(y_test, y_pred_svm)

"""**Visualisasi Algoritma Naive Bayes**"""

from sklearn.naive_bayes import GaussianNB

# Melatih model Naive Bayes
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)

# Evaluasi model Naive Bayes
def evaluate_nb(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    class_report = classification_report(y_true, y_pred, target_names=label_encoder.classes_)
    conf_matrix = confusion_matrix(y_true, y_pred)

    print("\n===== Evaluasi Model: Naive Bayes =====")
    print(f"Akurasi: {accuracy:.4f}\n")
    print("Laporan Klasifikasi:")
    print(class_report)

    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    plt.title('Matriks Kebingungan: Naive Bayes')
    plt.xlabel('Prediksi')
    plt.ylabel('Kebenaran')
    plt.show()

    return accuracy  # Mengembalikan akurasi

# Panggil fungsi evaluasi Naive Bayes
nb_accuracy = evaluate_nb(y_test, y_pred_nb)

"""**Visualisasi Algoritma Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

# Melatih model Decision Tree
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)

# Evaluasi model Decision Tree
def evaluate_dt(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    class_report = classification_report(y_true, y_pred, target_names=label_encoder.classes_)
    conf_matrix = confusion_matrix(y_true, y_pred)

    print("\n===== Evaluasi Model: Decision Tree =====")
    print(f"Akurasi: {accuracy:.4f}\n")
    print("Laporan Klasifikasi:")
    print(class_report)

    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    plt.title('Matriks Kebingungan: Decision Tree')
    plt.xlabel('Prediksi')
    plt.ylabel('Kebenaran')
    plt.show()

    return accuracy  # Mengembalikan akurasi

# Panggil fungsi evaluasi Decision Tree
dt_accuracy = evaluate_dt(y_test, y_pred_dt)

"""**Dokumentasi Visualisasi Perbandingan**"""

import matplotlib.pyplot as plt

# Menyimpan akurasi model dalam list
model_names = ['KNN', 'Random Forest', 'XGBoost', 'SVM', 'Naive Bayes', 'Decision Tree']
accuracies = [knn_accuracy, rf_accuracy, xgb_accuracy, svm_accuracy, nb_accuracy, dt_accuracy]

# Membuat plot horizontal bar untuk perbandingan akurasi model
plt.figure(figsize=(8, 5))
plt.barh(model_names, accuracies, color=['#FF9999', '#66B3FF', '#99FF99', '#FFCC99', '#FF6666', '#99CCFF'])
plt.xlim(0, 1)
plt.title('Perbandingan Akurasi Model')
plt.xlabel('Akurasi')
plt.ylabel('Model')

# Menambahkan nilai akurasi di sebelah bar
for i, v in enumerate(accuracies):
    plt.text(v + 0.01, i, f"{v:.2f}", va='center')

plt.show()

"""# **5. Kesimpulan**

Model untuk memprediksi kualitas apel telah berhasil dikembangkan menggunakan beberapa algoritma machine learning, termasuk KNN, Random Forest, SVM, Naive Bayes, Decision Tree, dan XGBoost. Model-model ini telah dilatih dan dievaluasi dengan menggunakan dataset yang relevan, menghasilkan metrik akurasi, presisi, dan recall yang menunjukkan kinerja yang baik dalam klasifikasi. Model ini dapat diterapkan untuk memprediksi kualitas apel dalam data nyata, memberikan nilai tambah bagi para petani dan produsen dalam meningkatkan hasil panen dan kualitas produk mereka.

Ke depan, terdapat beberapa area yang dapat dikembangkan lebih lanjut, seperti eksplorasi algoritma machine learning tambahan yang mungkin menawarkan kinerja yang lebih baik, serta penerapan pendekatan deep learning untuk menangkap pola yang lebih kompleks dalam data. Dengan pengembangan ini, diharapkan model dapat memberikan prediksi yang lebih akurat dan mendukung keputusan yang lebih baik dalam pengelolaan kualitas apel.

# ***Referensi***

*   [link text](https://revou.co/kosakata/eda)
*   [link text](https://www.kaggle.com/datasets/nelgiriyewithana/apple-quality/data)


*   [link text](https://aws.amazon.com/id/what-is/data-preparation/)
*   [link text](https://github.com/fauziahumri/MachineLearningTerapan/blob/main/MLT_Submission_1.ipynb)


*   [link text](https://github.com/unorderedlists/MLterapan-pertama/blob/main/notebook.ipynb)
*   [link text](https://github.com/ridwanabdiansah29/Submission-Dicoding-ML-Terapan1/blob/main/Ridwan_Abdiansah_MLT1.ipynb)
"""